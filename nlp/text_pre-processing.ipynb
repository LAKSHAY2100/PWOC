{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Natural Language Processing (NLP) - Quick Overview\n",
    "NLP is a branch of AI that helps machines understand, interpret, and generate human language. It is used in chatbots, translation, sentiment analysis, speech recognition, and more.\n",
    "\n",
    "Key NLP Concepts\n",
    "\n",
    "Tokenization – Splitting text into individual units (words or sentences).\n",
    "Example: \"AI is powerful.\" → [\"AI\", \"is\", \"powerful\", \".\"]\n",
    "\n",
    "Stemming – Reducing words to their root form by chopping off suffixes.\n",
    "Example: \"running\", \"runner\" → \"run\"\n",
    "\n",
    "Lemmatization – Converts words to their base (dictionary) form, considering context.\n",
    "Example: \"running\" → \"run\", \"better\" → \"good\"\n",
    "\n",
    "Stopwords – Common words that don’t add much meaning (e.g., is, the, and, in).\n",
    "Used to improve efficiency in text processing by removing them.\n",
    "\n",
    "Named Entity Recognition (NER) – Identifies and classifies entities in text (names, places, dates, etc.).\n",
    "\n",
    "    Example: \"Elon Musk founded Tesla in 2003.\"\n",
    "\n",
    "    Elon Musk → PERSON\n",
    "\n",
    "    Tesla → ORGANIZATION\n",
    "\n",
    "    2003 → DATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = \"\"\"\n",
    "Hello welcome to my channel.\n",
    "Let me start with my intro's My name is LAKSHAY!! , Whats yours.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Hello welcome to my channel.\n",
      "Let me start with my intro's My name is LAKSHAY!!\n",
      ", Whats yours.\n",
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "# sentence_tokenization\n",
    "\n",
    "#(corpus)paragraph -> (document)sentence\n",
    "from nltk.tokenize import sent_tokenize\n",
    "document = sent_tokenize(corpus)\n",
    "for i in document:\n",
    "    print(i)\n",
    "print(type(document))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello\n",
      "welcome\n",
      "to\n",
      "my\n",
      "channel\n",
      ".\n",
      "Let\n",
      "me\n",
      "start\n",
      "with\n",
      "my\n",
      "intro\n",
      "'s\n",
      "My\n",
      "name\n",
      "is\n",
      "LAKSHAY\n",
      "!\n",
      "!\n",
      ",\n",
      "Whats\n",
      "yours\n",
      ".\n",
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "# word_tokenization\n",
    "#  (corpus)paragraph -> words\n",
    "from nltk.tokenize import word_tokenize\n",
    "words = word_tokenize(corpus)\n",
    "for i in words:\n",
    "    print(i)\n",
    "print(type(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hello', 'welcome', 'to', 'my', 'channel', '.']\n",
      "['Let', 'me', 'start', 'with', 'my', 'intro', \"'s\", 'My', 'name', 'is', 'LAKSHAY', '!', '!']\n",
      "[',', 'Whats', 'yours', '.']\n"
     ]
    }
   ],
   "source": [
    "for sentence in document:\n",
    "    print(word_tokenize(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Kalam',\n",
       " 'was',\n",
       " 'born',\n",
       " 'in',\n",
       " 'a',\n",
       " 'town',\n",
       " 'in',\n",
       " 'Tamil',\n",
       " 'Nadu',\n",
       " 'state',\n",
       " 'to',\n",
       " 'a',\n",
       " 'fishing',\n",
       " 'boat',\n",
       " 'owner',\n",
       " 'from',\n",
       " 'a',\n",
       " 'once',\n",
       " 'wealthy',\n",
       " 'family',\n",
       " '.',\n",
       " 'The',\n",
       " 'youngest',\n",
       " 'of',\n",
       " 'five',\n",
       " 'siblings',\n",
       " ',',\n",
       " 'Kalam',\n",
       " 'persevered',\n",
       " 'with',\n",
       " 'his',\n",
       " 'education',\n",
       " 'despite',\n",
       " 'his',\n",
       " 'impoverished',\n",
       " 'circumstances',\n",
       " '.',\n",
       " 'He',\n",
       " 'earned',\n",
       " 'a',\n",
       " 'degree',\n",
       " 'in',\n",
       " 'aeronautical',\n",
       " 'engineering',\n",
       " 'from',\n",
       " 'the',\n",
       " 'Madras',\n",
       " 'Institute',\n",
       " 'of',\n",
       " 'Technology',\n",
       " 'and',\n",
       " 'in',\n",
       " '1958',\n",
       " 'joined',\n",
       " 'the',\n",
       " 'Defence',\n",
       " 'Research',\n",
       " 'and',\n",
       " 'Development',\n",
       " 'Organisation',\n",
       " '(',\n",
       " 'DRDO',\n",
       " ').',\n",
       " 'In',\n",
       " '1969',\n",
       " 'he',\n",
       " 'moved',\n",
       " 'to',\n",
       " 'the',\n",
       " 'Indian',\n",
       " 'Space',\n",
       " 'Research',\n",
       " 'Organisation',\n",
       " '(',\n",
       " 'ISRO',\n",
       " '),',\n",
       " 'where',\n",
       " 'he',\n",
       " 'was',\n",
       " 'project',\n",
       " 'director',\n",
       " 'of',\n",
       " 'the',\n",
       " 'SLV',\n",
       " '-',\n",
       " 'III',\n",
       " ',',\n",
       " 'the',\n",
       " 'first',\n",
       " 'satellite',\n",
       " 'launch',\n",
       " 'vehicle',\n",
       " 'that',\n",
       " 'was',\n",
       " 'both',\n",
       " 'designed',\n",
       " 'and',\n",
       " 'produced',\n",
       " 'in',\n",
       " 'India',\n",
       " '.',\n",
       " 'In',\n",
       " '1980',\n",
       " 'SLV',\n",
       " '-',\n",
       " 'III',\n",
       " 'successfully',\n",
       " 'released',\n",
       " 'a',\n",
       " 'satellite',\n",
       " 'called',\n",
       " 'Rohini',\n",
       " 'into',\n",
       " 'near',\n",
       " '-',\n",
       " 'Earth',\n",
       " 'orbit',\n",
       " ',',\n",
       " 'taking',\n",
       " 'India',\n",
       " '’',\n",
       " 's',\n",
       " 'space',\n",
       " 'program',\n",
       " 'to',\n",
       " 'the',\n",
       " 'international',\n",
       " 'stage',\n",
       " '.',\n",
       " 'Kalam',\n",
       " 'oversaw',\n",
       " 'further',\n",
       " 'development',\n",
       " 'of',\n",
       " 'launch',\n",
       " 'vehicle',\n",
       " 'technologies',\n",
       " 'at',\n",
       " 'ISRO',\n",
       " ',',\n",
       " 'including',\n",
       " 'the',\n",
       " 'Polar',\n",
       " 'Satellite',\n",
       " 'Launch',\n",
       " 'Vehicle',\n",
       " '.']"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this is word punctuation which consider each punctuation as a different object\n",
    "from nltk.tokenize import wordpunct_tokenize\n",
    "wordpunct_tokenize(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eating---> eat\n",
      "eats---> eat\n",
      "eaten---> eaten\n",
      "writing---> write\n",
      "writes---> write\n",
      "programming---> program\n",
      "programs---> program\n",
      "history---> histori\n",
      "finally---> final\n",
      "finalized---> final\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'congratul'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# stemming(PorterStemmer)\n",
    "from nltk.stem import PorterStemmer\n",
    "stemming = PorterStemmer()\n",
    "words = ['eating' , 'eats' , 'eaten' , 'writing' , 'writes' , 'programming' , 'programs' , 'history' , 'finally' , 'finalized']\n",
    "for word in words:\n",
    "    print(word  + \"---> \" + stemming.stem(word))\n",
    "\n",
    "# disadvantage(meaningless words are formed)\n",
    "stemming.stem('congratulations')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The--->The\n",
      "Eiffel--->Eiffel\n",
      "Tower--->Tower\n",
      "was--->be\n",
      "built--->build\n",
      "from--->from\n",
      "1887--->1887\n",
      "to--->to\n",
      "1889--->1889\n",
      "by--->by\n",
      "Gustave--->Gustave\n",
      "Eiffel--->Eiffel\n",
      ",--->,\n",
      "whose--->whose\n",
      "company--->company\n",
      "specialized--->specialize\n",
      "in--->in\n",
      "building--->build\n",
      "metal--->metal\n",
      "frameworks--->frameworks\n",
      "and--->and\n",
      "structures--->structure\n",
      ".--->.\n"
     ]
    }
   ],
   "source": [
    "# lemmatization (always gives meaningfull word)\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# it has pos tag which stands for POSITION\n",
    "# v --> verb\n",
    "# a --> adjective\n",
    "# n --> noun (by default)\n",
    "\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "for word in words:\n",
    "    print(word + '--->' + lemmatizer.lemmatize(word , pos='v'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'congratulation'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatizer.lemmatize('congratulations' , pos='n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing stop words (stop words are those words which are insignificant in a corpus like on,to,they,he, etc..)\n",
    "corpus = \"\"\"\n",
    "Kalam was born in a town in Tamil Nadu state to a fishing boat owner from a once wealthy family. The youngest of five siblings, Kalam persevered with his education despite his impoverished circumstances. He earned a degree in aeronautical engineering from the Madras Institute of Technology and in 1958 joined the Defence Research and Development Organisation (DRDO). In 1969 he moved to the Indian Space Research Organisation (ISRO), where he was project director of the SLV-III, the first satellite launch vehicle that was both designed and produced in India. In 1980 SLV-III successfully released a satellite called Rohini into near-Earth orbit, taking India’s space program to the international stage. Kalam oversaw further development of launch vehicle technologies at ISRO, including the Polar Satellite Launch Vehicle.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Lakshay\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# stopwords are already defined set of words which are different in different languages\n",
    "# downloading stop words\n",
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'me',\n",
       " 'my',\n",
       " 'myself',\n",
       " 'we',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'you',\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " \"you'll\",\n",
       " \"you'd\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " 'he',\n",
       " 'him',\n",
       " 'his',\n",
       " 'himself',\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'her',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'they',\n",
       " 'them',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'themselves',\n",
       " 'what',\n",
       " 'which',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'this',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'these',\n",
       " 'those',\n",
       " 'am',\n",
       " 'is',\n",
       " 'are',\n",
       " 'was',\n",
       " 'were',\n",
       " 'be',\n",
       " 'been',\n",
       " 'being',\n",
       " 'have',\n",
       " 'has',\n",
       " 'had',\n",
       " 'having',\n",
       " 'do',\n",
       " 'does',\n",
       " 'did',\n",
       " 'doing',\n",
       " 'a',\n",
       " 'an',\n",
       " 'the',\n",
       " 'and',\n",
       " 'but',\n",
       " 'if',\n",
       " 'or',\n",
       " 'because',\n",
       " 'as',\n",
       " 'until',\n",
       " 'while',\n",
       " 'of',\n",
       " 'at',\n",
       " 'by',\n",
       " 'for',\n",
       " 'with',\n",
       " 'about',\n",
       " 'against',\n",
       " 'between',\n",
       " 'into',\n",
       " 'through',\n",
       " 'during',\n",
       " 'before',\n",
       " 'after',\n",
       " 'above',\n",
       " 'below',\n",
       " 'to',\n",
       " 'from',\n",
       " 'up',\n",
       " 'down',\n",
       " 'in',\n",
       " 'out',\n",
       " 'on',\n",
       " 'off',\n",
       " 'over',\n",
       " 'under',\n",
       " 'again',\n",
       " 'further',\n",
       " 'then',\n",
       " 'once',\n",
       " 'here',\n",
       " 'there',\n",
       " 'when',\n",
       " 'where',\n",
       " 'why',\n",
       " 'how',\n",
       " 'all',\n",
       " 'any',\n",
       " 'both',\n",
       " 'each',\n",
       " 'few',\n",
       " 'more',\n",
       " 'most',\n",
       " 'other',\n",
       " 'some',\n",
       " 'such',\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'only',\n",
       " 'own',\n",
       " 'same',\n",
       " 'so',\n",
       " 'than',\n",
       " 'too',\n",
       " 'very',\n",
       " 's',\n",
       " 't',\n",
       " 'can',\n",
       " 'will',\n",
       " 'just',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'now',\n",
       " 'd',\n",
       " 'll',\n",
       " 'm',\n",
       " 'o',\n",
       " 're',\n",
       " 've',\n",
       " 'y',\n",
       " 'ain',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'ma',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\"]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# stopwrds in english language\n",
    "from nltk.corpus import stopwords\n",
    "stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['aber',\n",
       " 'alle',\n",
       " 'allem',\n",
       " 'allen',\n",
       " 'aller',\n",
       " 'alles',\n",
       " 'als',\n",
       " 'also',\n",
       " 'am',\n",
       " 'an',\n",
       " 'ander',\n",
       " 'andere',\n",
       " 'anderem',\n",
       " 'anderen',\n",
       " 'anderer',\n",
       " 'anderes',\n",
       " 'anderm',\n",
       " 'andern',\n",
       " 'anderr',\n",
       " 'anders',\n",
       " 'auch',\n",
       " 'auf',\n",
       " 'aus',\n",
       " 'bei',\n",
       " 'bin',\n",
       " 'bis',\n",
       " 'bist',\n",
       " 'da',\n",
       " 'damit',\n",
       " 'dann',\n",
       " 'der',\n",
       " 'den',\n",
       " 'des',\n",
       " 'dem',\n",
       " 'die',\n",
       " 'das',\n",
       " 'dass',\n",
       " 'daß',\n",
       " 'derselbe',\n",
       " 'derselben',\n",
       " 'denselben',\n",
       " 'desselben',\n",
       " 'demselben',\n",
       " 'dieselbe',\n",
       " 'dieselben',\n",
       " 'dasselbe',\n",
       " 'dazu',\n",
       " 'dein',\n",
       " 'deine',\n",
       " 'deinem',\n",
       " 'deinen',\n",
       " 'deiner',\n",
       " 'deines',\n",
       " 'denn',\n",
       " 'derer',\n",
       " 'dessen',\n",
       " 'dich',\n",
       " 'dir',\n",
       " 'du',\n",
       " 'dies',\n",
       " 'diese',\n",
       " 'diesem',\n",
       " 'diesen',\n",
       " 'dieser',\n",
       " 'dieses',\n",
       " 'doch',\n",
       " 'dort',\n",
       " 'durch',\n",
       " 'ein',\n",
       " 'eine',\n",
       " 'einem',\n",
       " 'einen',\n",
       " 'einer',\n",
       " 'eines',\n",
       " 'einig',\n",
       " 'einige',\n",
       " 'einigem',\n",
       " 'einigen',\n",
       " 'einiger',\n",
       " 'einiges',\n",
       " 'einmal',\n",
       " 'er',\n",
       " 'ihn',\n",
       " 'ihm',\n",
       " 'es',\n",
       " 'etwas',\n",
       " 'euer',\n",
       " 'eure',\n",
       " 'eurem',\n",
       " 'euren',\n",
       " 'eurer',\n",
       " 'eures',\n",
       " 'für',\n",
       " 'gegen',\n",
       " 'gewesen',\n",
       " 'hab',\n",
       " 'habe',\n",
       " 'haben',\n",
       " 'hat',\n",
       " 'hatte',\n",
       " 'hatten',\n",
       " 'hier',\n",
       " 'hin',\n",
       " 'hinter',\n",
       " 'ich',\n",
       " 'mich',\n",
       " 'mir',\n",
       " 'ihr',\n",
       " 'ihre',\n",
       " 'ihrem',\n",
       " 'ihren',\n",
       " 'ihrer',\n",
       " 'ihres',\n",
       " 'euch',\n",
       " 'im',\n",
       " 'in',\n",
       " 'indem',\n",
       " 'ins',\n",
       " 'ist',\n",
       " 'jede',\n",
       " 'jedem',\n",
       " 'jeden',\n",
       " 'jeder',\n",
       " 'jedes',\n",
       " 'jene',\n",
       " 'jenem',\n",
       " 'jenen',\n",
       " 'jener',\n",
       " 'jenes',\n",
       " 'jetzt',\n",
       " 'kann',\n",
       " 'kein',\n",
       " 'keine',\n",
       " 'keinem',\n",
       " 'keinen',\n",
       " 'keiner',\n",
       " 'keines',\n",
       " 'können',\n",
       " 'könnte',\n",
       " 'machen',\n",
       " 'man',\n",
       " 'manche',\n",
       " 'manchem',\n",
       " 'manchen',\n",
       " 'mancher',\n",
       " 'manches',\n",
       " 'mein',\n",
       " 'meine',\n",
       " 'meinem',\n",
       " 'meinen',\n",
       " 'meiner',\n",
       " 'meines',\n",
       " 'mit',\n",
       " 'muss',\n",
       " 'musste',\n",
       " 'nach',\n",
       " 'nicht',\n",
       " 'nichts',\n",
       " 'noch',\n",
       " 'nun',\n",
       " 'nur',\n",
       " 'ob',\n",
       " 'oder',\n",
       " 'ohne',\n",
       " 'sehr',\n",
       " 'sein',\n",
       " 'seine',\n",
       " 'seinem',\n",
       " 'seinen',\n",
       " 'seiner',\n",
       " 'seines',\n",
       " 'selbst',\n",
       " 'sich',\n",
       " 'sie',\n",
       " 'ihnen',\n",
       " 'sind',\n",
       " 'so',\n",
       " 'solche',\n",
       " 'solchem',\n",
       " 'solchen',\n",
       " 'solcher',\n",
       " 'solches',\n",
       " 'soll',\n",
       " 'sollte',\n",
       " 'sondern',\n",
       " 'sonst',\n",
       " 'über',\n",
       " 'um',\n",
       " 'und',\n",
       " 'uns',\n",
       " 'unsere',\n",
       " 'unserem',\n",
       " 'unseren',\n",
       " 'unser',\n",
       " 'unseres',\n",
       " 'unter',\n",
       " 'viel',\n",
       " 'vom',\n",
       " 'von',\n",
       " 'vor',\n",
       " 'während',\n",
       " 'war',\n",
       " 'waren',\n",
       " 'warst',\n",
       " 'was',\n",
       " 'weg',\n",
       " 'weil',\n",
       " 'weiter',\n",
       " 'welche',\n",
       " 'welchem',\n",
       " 'welchen',\n",
       " 'welcher',\n",
       " 'welches',\n",
       " 'wenn',\n",
       " 'werde',\n",
       " 'werden',\n",
       " 'wie',\n",
       " 'wieder',\n",
       " 'will',\n",
       " 'wir',\n",
       " 'wird',\n",
       " 'wirst',\n",
       " 'wo',\n",
       " 'wollen',\n",
       " 'wollte',\n",
       " 'würde',\n",
       " 'würden',\n",
       " 'zu',\n",
       " 'zum',\n",
       " 'zur',\n",
       " 'zwar',\n",
       " 'zwischen']"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# stopwords in german language\n",
    "stopwords.words('german')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Kalam was born in a town in Tamil Nadu state to a fishing boat owner from a once wealthy family.\n",
      "The youngest of five siblings, Kalam persevered with his education despite his impoverished circumstances.\n",
      "He earned a degree in aeronautical engineering from the Madras Institute of Technology and in 1958 joined the Defence Research and Development Organisation (DRDO).\n",
      "In 1969 he moved to the Indian Space Research Organisation (ISRO), where he was project director of the SLV-III, the first satellite launch vehicle that was both designed and produced in India.\n",
      "In 1980 SLV-III successfully released a satellite called Rohini into near-Earth orbit, taking India’s space program to the international stage.\n",
      "Kalam oversaw further development of launch vehicle technologies at ISRO, including the Polar Satellite Launch Vehicle.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['\\nKalam was born in a town in Tamil Nadu state to a fishing boat owner from a once wealthy family.',\n",
       " 'The youngest of five siblings, Kalam persevered with his education despite his impoverished circumstances.',\n",
       " 'He earned a degree in aeronautical engineering from the Madras Institute of Technology and in 1958 joined the Defence Research and Development Organisation (DRDO).',\n",
       " 'In 1969 he moved to the Indian Space Research Organisation (ISRO), where he was project director of the SLV-III, the first satellite launch vehicle that was both designed and produced in India.',\n",
       " 'In 1980 SLV-III successfully released a satellite called Rohini into near-Earth orbit, taking India’s space program to the international stage.',\n",
       " 'Kalam oversaw further development of launch vehicle technologies at ISRO, including the Polar Satellite Launch Vehicle.']"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import sent_tokenize\n",
    "sentences = sent_tokenize(corpus)\n",
    "for document in sentences:\n",
    "    print(document)\n",
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['kalam bear town tamil nadu state fish boat owner wealthy family .',\n",
       " 'the youngest five siblings , kalam persevere education despite impoverish circumstances .',\n",
       " 'he earn degree aeronautical engineer madras institute technology 1958 join defence research development organisation ( drdo ) .',\n",
       " 'in 1969 move indian space research organisation ( isro ) , project director slv-iii , first satellite launch vehicle design produce india .',\n",
       " 'in 1980 slv-iii successfully release satellite call rohini near-earth orbit , take india ’ space program international stage .',\n",
       " 'kalam oversee development launch vehicle technologies isro , include polar satellite launch vehicle .']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "for i in range(len(sentences)):\n",
    "    words = word_tokenize(sentences[i])\n",
    "    words = [lemmatizer.lemmatize(word.lower() , pos='v') for word in words if word not in set(stopwords.words('english'))]\n",
    "    sentences[i] = ' '.join(words)\n",
    "sentences "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I have three visions for India.',\n",
       " 'In 3000 years of our history, people from all over \\n               the world have come and invaded us, captured our lands, conquered our minds.',\n",
       " 'From Alexander onwards, the Greeks, the Turks, the Moguls, the Portuguese, the British,\\n               the French, the Dutch, all of them came and looted us, took over what was ours.',\n",
       " 'Yet we have not done this to any other nation.',\n",
       " 'We have not conquered anyone.',\n",
       " 'We have not grabbed their land, their culture, \\n               their history and tried to enforce our way of life on them.',\n",
       " 'Why?',\n",
       " 'Because we respect the freedom of others.That is why my \\n               first vision is that of freedom.',\n",
       " 'I believe that India got its first vision of \\n               this in 1857, when we started the War of Independence.',\n",
       " 'It is this freedom that\\n               we must protect and nurture and build on.',\n",
       " 'If we are not free, no one will respect us.',\n",
       " 'My second vision for India’s development.',\n",
       " 'For fifty years we have been a developing nation.',\n",
       " 'It is time we see ourselves as a developed nation.',\n",
       " 'We are among the top 5 nations of the world\\n               in terms of GDP.',\n",
       " 'We have a 10 percent growth rate in most areas.',\n",
       " 'Our poverty levels are falling.',\n",
       " 'Our achievements are being globally recognised today.',\n",
       " 'Yet we lack the self-confidence to\\n               see ourselves as a developed nation, self-reliant and self-assured.',\n",
       " 'Isn’t this incorrect?',\n",
       " 'I have a third vision.',\n",
       " 'India must stand up to the world.',\n",
       " 'Because I believe that unless India \\n               stands up to the world, no one will respect us.',\n",
       " 'Only strength respects strength.',\n",
       " 'We must be \\n               strong not only as a military power but also as an economic power.',\n",
       " 'Both must go hand-in-hand.',\n",
       " 'My good fortune was to have worked with three great minds.',\n",
       " 'Dr. Vikram Sarabhai of the Dept.',\n",
       " 'of \\n               space, Professor Satish Dhawan, who succeeded him and Dr. Brahm Prakash, father of nuclear material.',\n",
       " 'I was lucky to have worked with all three of them closely and consider this the great opportunity of my life.',\n",
       " 'I see four milestones in my career']"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  EXPLORING pos (PARTS OF SPEECH) TAG IN LEMMATIZATION\n",
    "paragraph = \"\"\"I have three visions for India. In 3000 years of our history, people from all over \n",
    "               the world have come and invaded us, captured our lands, conquered our minds. \n",
    "               From Alexander onwards, the Greeks, the Turks, the Moguls, the Portuguese, the British,\n",
    "               the French, the Dutch, all of them came and looted us, took over what was ours. \n",
    "               Yet we have not done this to any other nation. We have not conquered anyone. \n",
    "               We have not grabbed their land, their culture, \n",
    "               their history and tried to enforce our way of life on them. \n",
    "               Why? Because we respect the freedom of others.That is why my \n",
    "               first vision is that of freedom. I believe that India got its first vision of \n",
    "               this in 1857, when we started the War of Independence. It is this freedom that\n",
    "               we must protect and nurture and build on. If we are not free, no one will respect us.\n",
    "               My second vision for India’s development. For fifty years we have been a developing nation.\n",
    "               It is time we see ourselves as a developed nation. We are among the top 5 nations of the world\n",
    "               in terms of GDP. We have a 10 percent growth rate in most areas. Our poverty levels are falling.\n",
    "               Our achievements are being globally recognised today. Yet we lack the self-confidence to\n",
    "               see ourselves as a developed nation, self-reliant and self-assured. Isn’t this incorrect?\n",
    "               I have a third vision. India must stand up to the world. Because I believe that unless India \n",
    "               stands up to the world, no one will respect us. Only strength respects strength. We must be \n",
    "               strong not only as a military power but also as an economic power. Both must go hand-in-hand. \n",
    "               My good fortune was to have worked with three great minds. Dr. Vikram Sarabhai of the Dept. of \n",
    "               space, Professor Satish Dhawan, who succeeded him and Dr. Brahm Prakash, father of nuclear material.\n",
    "               I was lucky to have worked with all three of them closely and consider this the great opportunity of my life. \n",
    "               I see four milestones in my career\"\"\"\n",
    "sentences = nltk.sent_tokenize(paragraph)\n",
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# THES ARE VALUES OF pos (PARTS OF SPEECH)\n",
    "\n",
    "# Abbreviation\tMeaning\n",
    "# CC\tcoordinating conjunction\n",
    "# CD\tcardinal digit\n",
    "# DT\tdeterminer\n",
    "# EX\texistential there\n",
    "# FW\tforeign word\n",
    "# IN\tpreposition/subordinating conjunction\n",
    "# JJ\tThis NLTK POS Tag is an adjective (large)\n",
    "# JJR\tadjective, comparative (larger)\n",
    "# JJS\tadjective, superlative (largest)\n",
    "# LS\tlist market\n",
    "# MD\tmodal (could, will)\n",
    "# NN\tnoun, singular (cat, tree)\n",
    "# NNS\tnoun plural (desks)\n",
    "# NNP\tproper noun, singular (sarah)\n",
    "# NNPS\tproper noun, plural (indians or americans)\n",
    "# PDT\tpredeterminer (all, both, half)\n",
    "# POS\tpossessive ending (parent\\ ‘s)\n",
    "# PRP\tpersonal pronoun (hers, herself, him, himself)\n",
    "# PRP$\tpossessive pronoun (her, his, mine, my, our )\n",
    "# RB\tadverb (occasionally, swiftly)\n",
    "# RBR\tadverb, comparative (greater)\n",
    "# RBS\tadverb, superlative (biggest)\n",
    "# RP\tparticle (about)\n",
    "# TO\tinfinite marker (to)\n",
    "# UH\tinterjection (goodbye)\n",
    "# VB\tverb (ask)\n",
    "# VBG\tverb gerund (judging)\n",
    "# VBD\tverb past tense (pleaded)\n",
    "# VBN\tverb past participle (reunified)\n",
    "# VBP\tverb, present tense not 3rd person singular(wrap)\n",
    "# VBZ\tverb, present tense with 3rd person singular (bases)\n",
    "# WDT\twh-determiner (that, what)\n",
    "# WP\twh- pronoun (who)\n",
    "# WRB\twh- adverb (how)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('I', 'PRP'), ('three', 'CD'), ('visions', 'NNS'), ('India', 'NNP'), ('.', '.')]\n",
      "[('In', 'IN'), ('3000', 'CD'), ('years', 'NNS'), ('history', 'NN'), (',', ','), ('people', 'NNS'), ('world', 'NN'), ('come', 'VBP'), ('invaded', 'VBN'), ('us', 'PRP'), (',', ','), ('captured', 'VBD'), ('lands', 'NNS'), (',', ','), ('conquered', 'VBD'), ('minds', 'NNS'), ('.', '.')]\n",
      "[('From', 'IN'), ('Alexander', 'NNP'), ('onwards', 'NNS'), (',', ','), ('Greeks', 'NNP'), (',', ','), ('Turks', 'NNP'), (',', ','), ('Moguls', 'NNP'), (',', ','), ('Portuguese', 'NNP'), (',', ','), ('British', 'NNP'), (',', ','), ('French', 'NNP'), (',', ','), ('Dutch', 'NNP'), (',', ','), ('came', 'VBD'), ('looted', 'JJ'), ('us', 'PRP'), (',', ','), ('took', 'VBD'), ('.', '.')]\n",
      "[('Yet', 'RB'), ('done', 'VBN'), ('nation', 'NN'), ('.', '.')]\n",
      "[('We', 'PRP'), ('conquered', 'VBD'), ('anyone', 'NN'), ('.', '.')]\n",
      "[('We', 'PRP'), ('grabbed', 'VBD'), ('land', 'NN'), (',', ','), ('culture', 'NN'), (',', ','), ('history', 'NN'), ('tried', 'VBD'), ('enforce', 'JJ'), ('way', 'NN'), ('life', 'NN'), ('.', '.')]\n",
      "[('Why', 'WRB'), ('?', '.')]\n",
      "[('Because', 'IN'), ('respect', 'NN'), ('freedom', 'NN'), ('others.That', 'IN'), ('first', 'JJ'), ('vision', 'NN'), ('freedom', 'NN'), ('.', '.')]\n",
      "[('I', 'PRP'), ('believe', 'VBP'), ('India', 'NNP'), ('got', 'VBD'), ('first', 'JJ'), ('vision', 'NN'), ('1857', 'CD'), (',', ','), ('started', 'VBD'), ('War', 'NNP'), ('Independence', 'NNP'), ('.', '.')]\n",
      "[('It', 'PRP'), ('freedom', 'NN'), ('must', 'MD'), ('protect', 'VB'), ('nurture', 'NN'), ('build', 'NN'), ('.', '.')]\n",
      "[('If', 'IN'), ('free', 'JJ'), (',', ','), ('one', 'CD'), ('respect', 'NN'), ('us', 'PRP'), ('.', '.')]\n",
      "[('My', 'PRP$'), ('second', 'JJ'), ('vision', 'NN'), ('India', 'NNP'), ('’', 'NNP'), ('development', 'NN'), ('.', '.')]\n",
      "[('For', 'IN'), ('fifty', 'JJ'), ('years', 'NNS'), ('developing', 'VBG'), ('nation', 'NN'), ('.', '.')]\n",
      "[('It', 'PRP'), ('time', 'NN'), ('see', 'VB'), ('developed', 'JJ'), ('nation', 'NN'), ('.', '.')]\n",
      "[('We', 'PRP'), ('among', 'IN'), ('top', 'JJ'), ('5', 'CD'), ('nations', 'NNS'), ('world', 'NN'), ('terms', 'NNS'), ('GDP', 'NNP'), ('.', '.')]\n",
      "[('We', 'PRP'), ('10', 'CD'), ('percent', 'JJ'), ('growth', 'NN'), ('rate', 'NN'), ('areas', 'NNS'), ('.', '.')]\n",
      "[('Our', 'PRP$'), ('poverty', 'NN'), ('levels', 'NNS'), ('falling', 'VBG'), ('.', '.')]\n",
      "[('Our', 'PRP$'), ('achievements', 'NNS'), ('globally', 'RB'), ('recognised', 'VBN'), ('today', 'NN'), ('.', '.')]\n",
      "[('Yet', 'RB'), ('lack', 'JJ'), ('self-confidence', 'NN'), ('see', 'NN'), ('developed', 'JJ'), ('nation', 'NN'), (',', ','), ('self-reliant', 'JJ'), ('self-assured', 'JJ'), ('.', '.')]\n",
      "[('Isn', 'NNP'), ('’', 'NNP'), ('incorrect', 'NN'), ('?', '.')]\n",
      "[('I', 'PRP'), ('third', 'JJ'), ('vision', 'NN'), ('.', '.')]\n",
      "[('India', 'NNP'), ('must', 'MD'), ('stand', 'VB'), ('world', 'NN'), ('.', '.')]\n",
      "[('Because', 'IN'), ('I', 'PRP'), ('believe', 'VBP'), ('unless', 'IN'), ('India', 'NNP'), ('stands', 'VBZ'), ('world', 'NN'), (',', ','), ('one', 'CD'), ('respect', 'NN'), ('us', 'PRP'), ('.', '.')]\n",
      "[('Only', 'RB'), ('strength', 'NN'), ('respects', 'NNS'), ('strength', 'NN'), ('.', '.')]\n",
      "[('We', 'PRP'), ('must', 'MD'), ('strong', 'JJ'), ('military', 'JJ'), ('power', 'NN'), ('also', 'RB'), ('economic', 'JJ'), ('power', 'NN'), ('.', '.')]\n",
      "[('Both', 'DT'), ('must', 'MD'), ('go', 'VB'), ('hand-in-hand', 'NN'), ('.', '.')]\n",
      "[('My', 'PRP$'), ('good', 'JJ'), ('fortune', 'NN'), ('worked', 'VBD'), ('three', 'CD'), ('great', 'JJ'), ('minds', 'NNS'), ('.', '.')]\n",
      "[('Dr.', 'NNP'), ('Vikram', 'NNP'), ('Sarabhai', 'NNP'), ('Dept', 'NNP'), ('.', '.')]\n",
      "[('space', 'NN'), (',', ','), ('Professor', 'NNP'), ('Satish', 'NNP'), ('Dhawan', 'NNP'), (',', ','), ('succeeded', 'VBD'), ('Dr.', 'NNP'), ('Brahm', 'NNP'), ('Prakash', 'NNP'), (',', ','), ('father', 'RB'), ('nuclear', 'JJ'), ('material', 'NN'), ('.', '.')]\n",
      "[('I', 'PRP'), ('lucky', 'VBP'), ('worked', 'VBD'), ('three', 'CD'), ('closely', 'RB'), ('consider', 'VBP'), ('great', 'JJ'), ('opportunity', 'NN'), ('life', 'NN'), ('.', '.')]\n",
      "[('I', 'PRP'), ('see', 'VBP'), ('four', 'CD'), ('milestones', 'NNS'), ('career', 'NN')]\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(sentences)):\n",
    "    words = nltk.word_tokenize(sentences[i])\n",
    "    words = [word for word in words if word not in stopwords.words('english')] # removing stopwords \n",
    "    pos_tag = nltk.pos_tag(words) # take sentence or word and gave their corresponding pos tag\n",
    "    print(pos_tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  The/DT\n",
      "  (ORGANIZATION Eiffel/NNP Tower/NNP)\n",
      "  was/VBD\n",
      "  built/VBN\n",
      "  from/IN\n",
      "  1887/CD\n",
      "  to/TO\n",
      "  1889/CD\n",
      "  by/IN\n",
      "  (PERSON Gustave/NNP Eiffel/NNP)\n",
      "  ,/,\n",
      "  whose/WP$\n",
      "  company/NN\n",
      "  specialized/VBD\n",
      "  in/IN\n",
      "  building/NN\n",
      "  metal/NN\n",
      "  frameworks/NNS\n",
      "  and/CC\n",
      "  structures/NNS\n",
      "  ./.)\n"
     ]
    }
   ],
   "source": [
    "# NER (NAMED ENTITY RECOGNITION)\n",
    "\n",
    "sentence=\"The Eiffel Tower was built from 1887 to 1889 by Gustave Eiffel, whose company specialized in building metal frameworks and structures.\"\n",
    "words = nltk.word_tokenize(sentence)\n",
    "pos_tags=nltk.pos_tag(words)\n",
    "print(nltk.ne_chunk(pos_tags))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".conda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
